---
title: "ANÁLISIS DE COMPONENTES PRINCIPALES Y CLUSTER"
date: "3/4/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE, warning=FALSE , message=FALSE}
library(readxl)
library(corrplot)
library(heatmaply)
library(RColorBrewer)
library(pastecs)
library(stats)
library(FactoMineR)
library(factoextra)
library(ggplot2)
library(lattice)
library(NbClust)
library(tidyverse)  
library(cluster)    
library(dendextend)
library(forecast)
```

# 1. Calcular la matriz de correlaciones, y su representación gráfica ¿Cuáles son las variables más correlacionadas de forma inversa?

```{r cars}
# 1.1)
PROVINCIAS <- read_excel("Provincias.xlsx")
datos <- as.data.frame(PROVINCIAS)
rownames(datos)<-datos[,1] 
prov<-datos[,-1]

# 1.2) 
R<-cor(prov, method="pearson")
knitr::kable(R, digits =2,caption = "Correlaciones")

# 1.3) 
corrplot(R, type="upper", order="hclust", tl.col="black", tl.srt=90)
```

Usando los datos del fichero Excel 'Provincias.xlsx', que contiene 18 variables, calculamos la matriz de correlaciones. 

Asimismo, analizamos las correlaciones mediante una salida gráfica. Observamos en primer lugar que las correlaciones positivas se muestran en azul y las correlaciones negativas en rojo. La intensidad del color y el tamaño del círculo son proporcionales a los coeficientes de correlación.

De acuerdo con la matriz de correlación y la representación gráfica, observamos que las variables más correlacionadas de forma inversa son: Industria, TVF, Poblacion, CTH, Infor, Construccion, NumEmpresas, Ocupados, AFS, APT y PIB.

# 2. Realizar un análisis de componentes principales sobre la matriz de correlaciones, calculando 7 componentes. Estudiar los valores de los autovalores obtenidos y las gráficas que los resumen. ¿Cuál es el número adecuado de componentes?

```{r}
#2.1) 
fit<-PCA(prov,scale.unit=TRUE,ncp=7,graph=TRUE) 
summary(fit)

# 2.2)
eig<-get_eigenvalue(fit)
knitr::kable(eig, digits =2,caption = "Autovalores")

# 2.4)
fviz_eig(fit, geom="line") + theme_grey()

# 2.5) 
fviz_eig(fit,addlabels=TRUE)
```

Recordamos que el número de Componentes determina la proporción de variabilidad a explicar que se considere suficiente, como mínimo el 70%, pero si es posible en torno al 80-90%. Así que analizamos los eigenvalues para determinar el número adecuado de componentes. 

La proporción de varianza explicada por cada autovalor se da en la segunda columna en porcentaje. Observamos en este caso que el 63.7% (Dim.1) de la proporción de variabilidad se explica por este autovalor. Por lo tanto, el número adecuado de componentes es 4, ya que el 92.19% de la proporción de variabilidad total se explica por los 4 primeros porcentajes de los eigenvalues.

También se aprecia con los puntos de la gráfica que se nivelan. Recordmaos que se puede trazar una recta que aglutine en su entorno a los autovalores más pequeños y todos los que queden por encima corresponderían a las Componentes Principales retenidas.

Por otra parte, podemos determinar el número adecuado de componentes analizando las gráficas de eigenvalues. Llegamos a la misma observación: las 4 componentes principales explicarían el 92.19% de la varianza de las variables iniciales. Por lo tanto, parece adecuado retener las 4 primeras Componentes Principales.


# 3. Hacer de nuevo el análisis sobre la matriz de correlaciones pero ahora indicando el número de componentes principales que hemos decidido retener (Que expliquen aproximadamente el 90%). Sobre este análisis contestar los siguientes apartados.

```{r, include=FALSE}
# 3) 
fit<-PCA(prov,scale.unit=TRUE,ncp=4,graph=TRUE)
```

# a. Mostrar los coeficientes para obtener las componentes principales ¿Cuál es la expresión para calcular la primera Componente en función de las variables originales?

```{r}
# a.1) 
res.desc <- dimdesc(fit, axes = c(1,2,3), proba = 0.05)
res.desc$Dim.1

# a.2)   
knitr::kable(fit$svd$V, digits =3,caption = "Autovectores")
```

Observamos en las tablas que la primera dimensión está representada al inicio mayoremente por Ocupados, NumEmpresas Poblacion y Construccion.

Asimismo, la expresión para calcular el primer componente basado en las variables originales es la siguiente:
PC1 = 0.29Poblacion* + -0.10Mortalidad* + 0.04Natalidad* + 0.11IPC* + 0.29NumEmpresas* + 0.28Industria* + 0.29Construccion* + 0.29CTH* + 0.28Infor* + 0.29AFS¨* + 0.29APT* + 0.11TasaActividad* + -0.01TasaParo* + 0.29Ocupados* + 0.29PIB* + 0.01CANE* + 0.29TVF* + 0.17VS*

# b. Mostar una tabla con las correlaciones de las Variables con las Componentes Principales. Para cada Componente indicar las variables con las que está más correlacionada

```{r}
# b)
var<-get_pca_var(fit)
var$coord
knitr::kable(var$cor, digits =2,caption = "Correlaciones de la CP con las variables")
```

Observemos que la primera componente (alrededor de 0,99), tiene una correlación alta con las variables Población, NumEmpresas, Construccion, CTH, AFS, Ocupados, PIB y TVF.

Para la segunda componente, observamos que tiene un gran correlación solo con Natalidad (0.79) y TasaParo (0.73). También tiene una correlación negativa importante con Mortalidad (-0.84).

Para la tercer componente, vemos que la variable más correlacionada es CANE, con 0,84.

Finalmente, la cuarta componente no tiene variables correlacionadas significativas, aunque VS (0,55) y TasaActividad (0,45) tienen una cierta relevancia.

La siguiente representación gráfica nos puede ayudar a entender como están recogidas nuestras variables iniciales en las nuevas componentes, puesto que representa el coeficiente de correlación entre las variables y las nuevas componentes.


# c. Comentar los gráficos que representan las variables en los planos formados por las componentes, intentando explicar lo que representa cada componente

```{r }
#c) 

fviz_pca_var(fit, axes = c(1,2), col.var="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE )

fviz_pca_var(fit, axes = c(1,3), col.var="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE )

fviz_pca_var(fit, axes = c(2,3), col.var="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE )

fviz_pca_var(fit, axes = c(2,4), col.var="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE )

fviz_pca_var(fit, axes = c(3,4), col.var="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE )
```

- La componente 1 representa la Población, el NumEmpresas, la Industria, la Construccion, el CTH, el PIB, el Infor, el AFS, el APT, los Ocupados y el TVF.
  
- La componente 2 representa a la Mortalidad, Natalidad y la TasaParo.
  
- La componente 3 representa sobre todo la información de la variable CANE.

- La componente 4 representa sobre todo la información de la variable IPC.

# d. Mostrar la tabla y los gráficos que nos muestran la proporción de la varianza de cada variable que es explicado por cada componente. ¿Cuál de las variables es la que está peor explicada?

```{r}
# d.1) 
knitr::kable(var$cos2, digits =2,caption = "Cosenos al cuadrado")

# d.2)
corrplot(var$cos2,is.corr=FALSE)

# d.3)
fviz_cos2(fit,choice="var",axes=1:4)

# d.4)
var$contrib
```
En los gráficos que nos muestran la proporción de la varianza de cada variable que es explicado por cada componente:

- Componente 1: Gráficamente se muestra que las variables (en Dim1) representan principalmente a las variables Población, NumEmpresas, Industria, Construccion, CTH, Infor, AFS, APT, Ocupados, PIB y TVF.

- Componente 2: La segunda (Dim2) explica Mortalidad y Natalidad y podríamos incluir TasaParo.
 
- Componente 3: La tercera (Dim3) representa principalmente CANE.

- Componente 4: La cuarta (Dim4) representa sobre todo IPC 

Finalmente, la variable que está peor explicada es VS, lo que se observa también en el corrplot y en las tablas.

# e. Mostrar la tabla y los gráficos que nos muestran el porcentaje de la varianza de cada Componente que es debido a cada variable. ¿Que variables contribuyen más a cada Componente?

```{r}
# e.1) 
knitr::kable(var$contrib, digits =2,caption = "Contribuciones")

# e.2)
corrplot(var$contrib,is.corr=FALSE)

# e.3)
fviz_contrib(fit,choice="var",axes=1)
fviz_contrib(fit,choice="var",axes=2)
fviz_contrib(fit,choice="var",axes=3)
fviz_contrib(fit,choice="var",axes=4)
```

- Componente 1: observamos que Población, NumEmpresas, Industria, Construccion, CTH, Infor, AFS, APT, Ocupados, PIB y TVF contribuyen casi en la misma proporción.

- Componente 2: Mortalidad, Natalidad, TasaParo y IPC contribuyen mayormente 

- Componente 3: sobre todo CANE contribuye.

- Componente 4: VS, TasaActividad y IPC contribuyen principalmente.


# f. Sobre los gráficos que representan las observaciones en los nuevos ejes y el gráfico Biplot, teniendo en cuenta la posición de las provincias en el gráfico, comentar las provincias que tienen una posición más destacada en cada componente, en positivo o negativo, ¿Qué significa esto en términos socioeconómicos para estas provincias?

```{r}
#f1) 
fviz_pca_ind(fit, col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE)

# f.2)
fviz_pca_ind(fit, axes = c(1, 2), gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
fviz_pca_ind(fit, axes = c(2, 3), col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
fviz_pca_ind(fit, axes = c(3, 4), col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

# f.3) Representación conjunta de los individuos y las variables en los plan os de las CP
fviz_pca_biplot(fit, repel = TRUE,axes = c(1, 2), col.var = "#2E9FDF", col.ind = "#696969")
fviz_pca_biplot(fit, repel = TRUE,axes = c(1, 3), col.var = "#2E9FDF", col.ind = "#696969")
fviz_pca_biplot(fit, repel = TRUE,axes = c(2, 3), col.var = "#2E9FDF", col.ind = "#696969")
fviz_pca_biplot(fit, repel = TRUE,axes = c(2, 4), col.var = "#2E9FDF", col.ind = "#696969")
fviz_pca_biplot(fit, repel = TRUE,axes = c(3, 4), col.var = "#2E9FDF", col.ind = "#696969")
```

De las provincias más destacadas en cada componente, en positivo o negativo:

Vemos que Madrid y Barcelona tienen un comportamiento similar. Tienen un valor alto de la CP1 lo que significa alto porcentaje Población, NumEmpresas, Industria, Construccion. Se trata de provincias más desarrolladas ya que emplean a la mayoria de la población del país, con un número de empresas igual de importante y una participación en el PIB considerable. Sin embargo, tienen un tasa de Natalidad negativa.

Valencia y Alicante también son similares, ya que tienen un alto porcentaje de VS (Viviendas secundarias) y una TasaActividad alta, lo que puede ser el resultado de las actividades turísticas nacionales. Además, un CANE muy importante significa que son regiones con una agricultura relavante.

Melilla y Ceuta tienen una tasa de paro importante (negativa) y al contrario una Natalidad significativa de manera positiva. Se trata de provincias pobladas pero con poca actividad económica.

Zamora y Ourense tienen mucha Mortalidad, así como un tasa de paro significativa. Se trata de provincias poca desarrolladas.


# g. Si tuviéramos que construir un índice que valore de forma conjunta el desarrollo económico de una provincia, como se podría construir utilizando una combinación lineal de todas las variables. ¿Cuál sería el valor de dicho índice en Madrid? ¿Cual sería su valor en Melilla?

```{r}
# g.1)
ind<-get_pca_ind(fit)
knitr::kable(ind$coord, digits =3,caption = "Valores de los individuo s en las Cp")

# g.2)
data <- data.frame(ind$coord[,1])
data

# g.3)
y=data[,1]
x= rownames(data)

# g4)
ggplot(data, aes(x=x, y=y)) +
  geom_segment( aes(x=x, xend=x, y=0, yend=y)) +
  geom_point( size=5, color="red", fill=alpha("orange", 0.3), alpha=0.7, shape=21, stroke=2) + theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Con un índice que valore de forma conjunta el desarrollo económico de una provincia:

- El valor de dicho índice en Madrid es 16,77.

- El valor de dicho índice en Melilla es -2,21.

# 4. Representar un mapa de calor de la matriz de datos, estandarizado y sin estandarizar para ver si se detectan inicialmente grupos de provincias.


```{r}
# 4.1.1) 
heatmaply(prov, seriate = "mean", row_dend_left = TRUE, plot_method = "plotly")

# 4.1.2) 
d <- dist(prov, method = "euclidean")

# 4.1.3)
heatmaply(as.matrix(d), seriate = "OLO", row_dend_left = TRUE, plot_method = "plotly")

# 4.1.4)
ggheatmap(as.matrix(d), seriate="mean")

# 4.1.5)
fviz_dist(d, show_labels = TRUE)


#Standardize the data 
datos_ST <- scale(prov)

# 4.2.1)
d_st <- dist(datos_ST, method = "euclidean")

# 4.2.2)
fviz_dist(d_st)

# 4.2.3) 
heatmaply(as.matrix(datos_ST), seriate = "mean", row_dend_left = TRUE, plot_method = "plotly")

# 4.2.4) 
heatmaply(as.matrix(d_st), seriate = "mean", row_dend_left = TRUE, plot_method = "plotly")

# 4.2.5) 
heatmaply(scale(prov), xlab = "Variables", ylab = "Provinces", main = "Raw data")
```

En el mapa de calor de la matriz de datos, tanto estandarizado como sin estandarizar, observamos que se detectan inicialmente cuatro grupos de provincias:

- Grupo 1: Madrid y Barcelona.
- Grupo 2: Entre otras provincias, Valencia y Alicante.
- Grupo 3: Entre otras provincias, Cádiz y Málaga.
- Grupo 4: Entre otras provincias, Zamora y Soria.

Madrid y Barcelona tienen una distancia muy superior con el resto de las provincias.

# 5. Realizar un análisis Jerárquico de clusters para determinar si existen grupos de provincias con comportamiento similar.

# a. A la vista del dendrograma ¿Cuántos clusters recomendarías?

```{r}
# a)
res.hc_st <- hclust(d_st, method="ward.D2")
fviz_dend(res.hc_st, cex = 0.5)
```

-A la vista del dendrograma, el número de clusters recomendado es 4.
-Significa que en nuestro caso vemos la composición para k = 4.

# b. Representar los individuos agrupados según el número de clusters elegido.

```{r}
# b.1)
grp <- cutree(res.hc_st, k = 4)

# b.2) 
knitr::kable(table(grp), caption = "Número de individuos por cluster")

# b.3)
rownames(prov)[grp == 4]

# b.4) 
fviz_dend(res.hc_st, k = 4, 
          cex = 0.5,
          k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
          color_labels_by_k = TRUE, 
          rect = TRUE)

# b.5)
fviz_cluster(list(data = datos_ST, cluster = grp),
             palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"), 
             ellipse.type = "convex", repel = TRUE, 
             show.clust.cent = FALSE, ggtheme = theme_minimal())

# b.6)
res.agnes <- agnes(x =prov, 
                   stand = TRUE,
                   metric = "euclidean", 
                   method = "ward")
# b.7)
fviz_dend(res.agnes, cex = 0.6, k = 4)
```

Representamos los individuos agrupados según el número de clusters elegido, destacados con colores diferentes, mediante la función fviz_dend.

La función agnes, que directamente estandariza, calcula las distancias entre individuos y realiza el cluster jerárquico. Observemos que la función Agnes actúa directamente sobre los datos, no sobre la matriz de distancias. Por ello, la función no agrupa exactamente las mismas provincias, sobre todo en el cluster 2, ya que antes solo estaban Valencia y Alicante. 

# c. ¿Qué número óptimo de clusters nos indican los criterios Silhoutte y de Elbow?

```{r}
# c.1) Elbow 
fviz_nbclust(datos_ST, kmeans, method = "wss") + 
  geom_vline(xintercept = 4, linetype = 2)+ 
  labs(subtitle = "Elbow method")

# C.2) Silhouette
fviz_nbclust(datos_ST, kmeans, method = "silhouette")+ 
  labs(subtitle = "Silhouette method")
```

Los criterios Silhoutte y de Elbow nos indican el número óptimo de clusters.

- Basándonos en Elbow, el número óptimo de clusters es 4.
- Basándonos en Silhouette, el número óptimo de clusters es 2.

# d. Con el número de clusters decidido en el apartado anterior realizar un agrupamiento no jerárquico.

# i. Representar los clusters formados en los planos de las Componentes principales. Relacionar la posición de cada cluster en el plano con lo que representa cada componente principal.

```{r}
# i.1) 
RNGkind(sample.kind ="Rejection") 
set.seed(1234)

# i.2) 
km.res <- kmeans(datos_ST, 4)
head(km.res$cluster, 20)

# i.3) 
fviz_cluster(km.res, datos_ST)

# i.4)
fviz_cluster(km.res,datos_ST, palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"), ellipse.type = "convex", repel = TRUE, show.clust.cent = FALSE, ggtheme = theme_minimal())
```

- Cluster 1 se sitúa principalmente en la parte negativa se debe al hecho de que tiene una tasa de paro importante, pero una tasa de natalidad positiva. En ciertas provincias, como Baleares, tienen una tasa de Activdad positiva, por ello el cluster se sitúa en el medio, más o menos entre el cluster 2 y 3. 

- Cluster 2, que se posiciona casi al extremo, con entre otras provincias Jaén y Zamora, presenta una tasa importante de TasaParo y poca población, natalidad, TasaActividad, de acuerdo con  lo que representa la componente 4. Se sitúa más cerca del primer cluster que del tercer cluster, y tiene casi todo en negativo.

- Cluster 3, con entre otras provincias, Sevilla, Valencia y Alicante, se posiciona en el medio, con una mayoridad en positivo ya que  presenta una tasa importante de Natalidad, CTH, TasaCtividad, sobre todo de CANE, así como poca  mortalidad. La distancia entre las provincias de este cluster y las otras es mediana aunque se posiciona más cerca del primer cluster que del cuarto, de acuerdo con  lo que representa la componente 2.

- Cluster 4, con Barcelona y Madrid, presenta una alta correlación con la primer componente, lo que podría significar que las provincias tengan un número importante de empresas y contribuyan de manera significativa al PIB. La distancia entre las provincias de este cluster y las otras se destaca claramente en los gráficos.


# ii. Evaluar la calidad de los clusters.

```{r}
# ii)
sil <- silhouette(km.res$cluster, dist(datos_ST)) 
rownames(sil) <- rownames(prov)
fviz_silhouette(sil)
```
Las siluetas se encuentran entre -1 y 1. Si la silueta está próxima a 1 eso querría indicar que la observación se encuentra bien agrupada, mientras que si vale 0 indica que la observación podría pertenecer a su cluster actual o a otro cercano a él. Si la silueta es negativa indicaría una mala agrupación para la observación.

En nuestro ejemplo, la mayoría de las provincias están bien agrupadas, aunque haya una parte negativa en el primer cluster.
De hecho, el cluster 1 está mal clasificado porque su silueta es negativa.

Por ello, probamos de nuevo, con 2 Clusters, que es lo que nos recomienda el criterio Silhouette.

```{r}
RNGkind(sample.kind = "Rejection")
set.seed(1234)
km.res2 <- kmeans(datos_ST, 2) 
fviz_cluster(km.res2, datos_ST)
sil2 <- silhouette(km.res2$cluster, dist(datos_ST))
fviz_silhouette(sil2)
```

Se aprecia que ahora no existen observaciones con valor de la silueta negativo.

# e. Explicar las provincias que forman cada uno de los clusters y comentar cuales son las características socioeconómicas que las hacen pertenecer a dicho cluster.

```{r}
# e.1) 
ordenado<-sort(km.res$cluster)
knitr::kable(ordenado, digits =2, caption = "Provincias y clusters")

print(km.res)

# e.2) 
knitr::kable(km.res$centers, digits =2,caption = "Estadísticos de los clusters, datos STD")

# e.3)
EsT_Clus<-aggregate(prov, by=list(km.res$cluster),mean) 
knitr::kable(EsT_Clus, digits =2,caption = "Estadísticos de los clusters")
```

- Cluster 1: Las características socioeconómicas que hacen pertenecer a las provincias a dicho cluster es el hecho de tener una fuerte Natalidad positiva y una mortalidad negativa. Tienen una TasaActividad positiva y una Tasa Paro negativa, por lo que suponemos que hay una cierta actividad económica, pero donde la población no puede permanecer por falta de empresas y de industria en las áreas. De hecho, el cluster 1 tiene datos similares a los del cluster 2.

- Cluster 2: Las características socioeconómicas que hacen a las provincias pertenecer a dicho cluster se reflejan claramente en el hecho de que se trata de las provincias de industrialización inducida y escasa, con poca natalidad y poca tasa de actividad. De hecho, la llamamos la España 'vacía'. Tiene todo en negativo; salvo en IPC y sobre todo la Mortalidad, lo que confirma que se trata de provincias con poca actividad. Por ello, el cluster 2 es el único con tantas variables negativas.

- Cluster 3: Las características socioeconómicas que hacen a las provincias pertenecer a dicho cluster son claramente el hecho de tener espacios agrícolas productivos (tasa CANE importante) y formar parte de áreas en desarrollo que contribuyen al PIB de manera positiva, aunque en poca medida. Se aprecia que la tasa de paro es positiva, lo que confirma que las provincias no estan completamente desarrolladas, sino en expansión, teniendo en cuenta que la tasa Comercio, transporte y hostelería y la tasa actividad son positivas y favorables. En efecto, las medias de las variables en el cluster 3 son casi todas positivas, pero se quedan lejos de las medias del cluster 4.

- Cluster 4: El tercer cluster reagrupa las provincias con un fuerte desarrollo económico debido al número de empresas y la población importante. Con una contribución alta al PIB, una tasa de industria, construccion, CTH y Infor importante se trata de provincias dinámicas y consolidas. Por ello, las medias de las variables en el cluster 4 son mayores que la de tres otros clusters.


